{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import (RandomForestClassifier,GradientBoostingClassifier)\n",
    "from sklearn import linear_model\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import linear_model\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparacion de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_postulaciones(size=None):\n",
    "    postulaciones = pd.read_csv('data/FiubaHasta15Abril/fiuba_4_postulaciones.csv', nrows =size).drop_duplicates(subset=['idpostulante', 'idaviso'], keep='last')\n",
    "    columns_rename = {'idaviso': 'id_aviso', 'idpostulante': 'id_postulante', 'fechapostulacion': 'fecha_postulacion'}\n",
    "    postulaciones = postulaciones.rename(columns=columns_rename)\n",
    "    postulaciones['fecha_postulacion']=pd.to_datetime(postulaciones['fecha_postulacion'])\n",
    "    return postulaciones\n",
    "\n",
    "def get_vistas(size=None):\n",
    "    vistas1 = pd.read_csv('data/FiubaHasta15Abril/fiuba_3_vistas.csv', nrows =size)\n",
    "    vistas2 = pd.read_csv('data/FiubaDesde15Abril/fiuba_3_vistas.csv', nrows =size)\n",
    "    vistas3 = pd.read_csv('data/fiuba_3_vistas.csv', nrows =size)\n",
    "    vistas = pd.concat([vistas1, vistas2, vistas3])\n",
    "    vistas_sumarizadas = vistas.groupby(['idpostulante', 'idAviso'], as_index=False)['timestamp'].count()\n",
    "    columns_rename = {'idAviso': 'id_aviso', 'idpostulante': 'id_postulante', 'timestamp': 'visualizaciones'}\n",
    "    vistas_sumarizadas = vistas_sumarizadas.rename(columns=columns_rename)\n",
    "    \n",
    "    return vistas_sumarizadas\n",
    "\n",
    "\n",
    "# TOKENS - CHARLY BEGIN\n",
    "def tokens(doc):\n",
    "    return (tok.lower() for tok in re.findall(r\"\\w+\", doc))\n",
    "\n",
    "\n",
    "def token_freqs(doc):\n",
    "    freq = defaultdict(int)\n",
    "    for tok in tokens(doc):\n",
    "        freq[tok] += 1\n",
    "    return freq\n",
    "\n",
    "# TOKENS - CHARLY END\n",
    "\n",
    "def get_avisos_detalle():\n",
    "    avisos1 = pd.read_csv('data/fiuba_6_avisos_detalle.csv')\n",
    "    avisos2 = pd.read_csv('data/FiubaDesde15Abril/fiuba_6_avisos_detalle.csv')\n",
    "    avisos3 = pd.read_csv('data/FiubaHasta15Abril/fiuba_6_avisos_detalle.csv')\n",
    "    avisos4 = pd.read_csv('data/fiuba_6_avisos_detalle_missing_nivel_laboral.csv')        \n",
    "    avisos_detalle = pd.concat([avisos1,avisos2,avisos3,avisos4]).drop_duplicates(subset=['idaviso'], keep='last').reset_index(drop=True)\n",
    "    columns_rename = {'idpostulante': 'id_postulante', 'idaviso': 'id_aviso'}\n",
    "    avisos_detalle = avisos_detalle.rename(columns=columns_rename)\n",
    "    to_nivel_laboral_nro = {'Senior / Semi-Senior' : 2, 'Junior':1, 'Otro':0,\n",
    "       'Jefe / Supervisor / Responsable':3,\n",
    "       'Gerencia / Alta Gerencia / Dirección':4}\n",
    "    to_tipo_trabajo_nro={'Full-time':0, 'Part-time':1, 'Teletrabajo':2, 'Por Horas':3, 'Pasantia':4,\n",
    "       'Temporario':5, 'Por Contrato':6, 'Fines de Semana':7, 'Primer empleo':8,\n",
    "       'Voluntario':9}\n",
    "    to_nombre_area_numero = pd.Series(avisos_detalle['nombre_area'].unique()).to_dict()\n",
    "    to_nombre_area_numero  = {v: k for k, v in to_nombre_area_numero.items()}\n",
    "    avisos_detalle['nivel_laboral_nro']= avisos_detalle['nivel_laboral'].map(to_nivel_laboral_nro)\n",
    "    avisos_detalle['tipo_de_trabajo_nro'] = avisos_detalle['tipo_de_trabajo'].map(to_tipo_trabajo_nro)\n",
    "    avisos_detalle['nombre_area_nro'] = avisos_detalle['nombre_area'].map(to_nombre_area_numero)\n",
    "\n",
    "    h = FeatureHasher(n_features = 40, non_negative=True, input_type='string', dtype='float32')\n",
    "    # BEGIN FIX CHARLY\n",
    "    avisos_detalle['titulo_as_token_freq'] = avisos_detalle.titulo.apply(lambda x: token_freqs(x))\n",
    "    #x = h.transform(avisos_detalle['titulo'])\n",
    "    # en lugar de usar el titulo uso un token dict\n",
    "    x = h.transform(avisos_detalle['titulo_as_token_freq'])\n",
    "    avisos_detalle['titulo'] = list(x.toarray())\n",
    "\n",
    "    titulos_como_lista = avisos_detalle.titulo.apply(pd.Series)\n",
    "    avisos_detalle = pd.merge(avisos_detalle, titulos_como_lista, left_index = True, right_index = True)\n",
    "    avisos_detalle = avisos_detalle.drop(['titulo'], axis=1)  \n",
    "\n",
    "    return avisos_detalle\n",
    "\n",
    "def get_year_of_birth(postulantes_genero_edad):\n",
    "    return (pd.to_datetime\n",
    "            (postulantes_genero_edad['fechanacimiento'], errors='coerce', format='%Y-%m-%d')\n",
    "            .dt.year)\n",
    "\n",
    "def get_age(yearOfBirth):\n",
    "    return 2018 - yearOfBirth\n",
    "    \n",
    "def get_age_range(yearOfBirth):\n",
    "    age = get_age(yearOfBirth)\n",
    "    if(age<25): return 'Entre 18 y 24'\n",
    "    if(age<30): return 'Entre 25 y 30'\n",
    "    if(age<35): return 'Entre 30 y 35'\n",
    "    if(age<40): return 'Entre 35 y 40'\n",
    "    if(age<45): return 'Entre 40 y 45'\n",
    "    if(age<50): return 'Entre 45 y 50'\n",
    "    return 'Mayor de 50'\n",
    "\n",
    "def get_order_for_age_range():\n",
    "    return ['Entre 18 y 24', 'Entre 25 y 30','Entre 30 y 35','Entre 35 y 40','Entre 40 y 45','Entre 45 y 50', 'Mayor de 50']\n",
    "\n",
    "def get_postulantes_nivel_educativo_para(path):\n",
    "    postulantes_nivel_educativo = pd.read_csv(path)\n",
    "    columns_rename = {'idpostulante': 'id_postulante', 'nombre': 'formacion_postulante', 'estado': 'estado_formacion_postulante'}\n",
    "    postulantes_nivel_educativo=postulantes_nivel_educativo.rename(columns=columns_rename)\n",
    "    formacion_to_number={'Secundario' : 10, 'Otro': 20, 'Terciario/Técnico' : 30, 'Universitario' : 40, 'Posgrado' : 50,\n",
    "    'Master' : 50, 'Doctorado' : 50}\n",
    "    postulantes_nivel_educativo['formacion_postulante_numero']=postulantes_nivel_educativo['formacion_postulante'].map(formacion_to_number);\n",
    "    estado_to_number = {'En Curso': 4, 'Abandonado': 0, 'Graduado': 8}\n",
    "    postulantes_nivel_educativo['estado_formacion_postulante_numero']=postulantes_nivel_educativo['estado_formacion_postulante'].map(estado_to_number)\n",
    "    postulantes_nivel_educativo['nivel_educativo_postulante_numero'] = postulantes_nivel_educativo['formacion_postulante_numero'] + postulantes_nivel_educativo['estado_formacion_postulante_numero']\n",
    "    postulantes_nivel_educativo['nivel_educativo_postulante_texto'] = postulantes_nivel_educativo['formacion_postulante'] + ' - ' + postulantes_nivel_educativo['estado_formacion_postulante']\n",
    "    relevant_columns = ['id_postulante','nivel_educativo_postulante_texto', 'nivel_educativo_postulante_numero']\n",
    "    postulantes_nivel_educativo = postulantes_nivel_educativo[relevant_columns]\n",
    "    grouped=postulantes_nivel_educativo.groupby(['id_postulante']).agg({'nivel_educativo_postulante_numero':['max']}) \n",
    "    df=grouped.reset_index()\n",
    "    df.columns = ['id_postulante', 'maximo_nivel_educativo_postulante']\n",
    "    return df\n",
    "\n",
    "def get_postulantes_nivel_educativo():\n",
    "    postulantes1 = get_postulantes_nivel_educativo_para('data/fiuba_1_postulantes_educacion.csv')\n",
    "    postulantes2 = get_postulantes_nivel_educativo_para('data/FiubaDesde15Abril/fiuba_1_postulantes_educacion.csv')\n",
    "    postulantes3 = get_postulantes_nivel_educativo_para('data/FiubaHasta15Abril/fiuba_1_postulantes_educacion.csv')\n",
    "    return pd.concat([postulantes1,postulantes2,postulantes3]).drop_duplicates(subset=['id_postulante'], keep='last').reset_index(drop=True)\n",
    "\n",
    "def get_postulantes_genero_edad():\n",
    "    postulantes1 = pd.read_csv('data/fiuba_2_postulantes_genero_y_edad.csv')\n",
    "    postulantes2 = pd.read_csv('data/FiubaDesde15Abril/fiuba_2_postulantes_genero_y_edad.csv')\n",
    "    postulantes3 = pd.read_csv('data/FiubaHasta15Abril/fiuba_2_postulantes_genero_y_edad.csv')\n",
    "    postulantes_genero_edad = pd.concat([postulantes1,postulantes2,postulantes3]).drop_duplicates(subset=['idpostulante'], keep='last').reset_index(drop=True)\n",
    "    postulantes_genero_edad['año_nacimiento_postulante']=get_year_of_birth(postulantes_genero_edad)\n",
    "    postulantes_genero_edad['edad_postulante']=postulantes_genero_edad['año_nacimiento_postulante'].map(get_age, na_action=None)\n",
    "    postulantes_genero_edad['rango_edad_postulante']=postulantes_genero_edad['año_nacimiento_postulante'].map(get_age_range, na_action=None)\n",
    "    columns_rename = {'idpostulante': 'id_postulante', 'fechanacimiento': 'fecha_nacimiento_postulante', 'sexo': 'genero_postulante'}\n",
    "    postulantes_genero_edad = postulantes_genero_edad.rename(columns=columns_rename)\n",
    "    postulantes_genero_edad = postulantes_genero_edad[['id_postulante', 'genero_postulante', 'fecha_nacimiento_postulante', 'edad_postulante', 'rango_edad_postulante']]\n",
    "    postulantes_genero_edad['genero_postulante_nro'] = postulantes_genero_edad['genero_postulante'].map({'FEM': 0, 'MASC': 1, 'NO_DECLARA': 2})\n",
    "    return postulantes_genero_edad\n",
    "\n",
    "def get_postulantes_limpios():\n",
    "    postulantes = pd.merge(get_postulantes_genero_edad(), get_postulantes_nivel_educativo(), on='id_postulante', how='outer')\n",
    "    order_for_columns = ['id_postulante','edad_postulante', 'genero_postulante', 'genero_postulante_nro', 'maximo_nivel_educativo_postulante']\n",
    "    return postulantes[order_for_columns]\n",
    "\n",
    "def get_detalle_postulaciones(size=None):\n",
    "    postulaciones = get_postulaciones(size)\n",
    "    avisos = get_avisos_detalle()\n",
    "    postulantes = get_postulantes_limpios()\n",
    "    detalle_postulaciones = pd.merge(postulantes, postulaciones, on='id_postulante', how='inner') \n",
    "    detalle_postulaciones = pd.merge(detalle_postulaciones, avisos, on='id_aviso', how='inner')\n",
    "    \n",
    "    return detalle_postulaciones\n",
    "\n",
    "def get_detalle_vistas(size=None):\n",
    "    vistas = get_vistas(size)\n",
    "    avisos = get_avisos_detalle()\n",
    "    postulantes = get_postulantes_limpios()\n",
    "    detalle_vistas = pd.merge(postulantes, vistas, on='id_postulante', how='inner') \n",
    "    detalle_vistas = pd.merge(detalle_vistas, avisos, on='id_aviso', how='inner')\n",
    "    return detalle_vistas\n",
    "\n",
    "def x_entrenamiento():\n",
    "    return ['edad_postulante', 'genero_postulante_nro', 'maximo_nivel_educativo_postulante', 'nivel_laboral_nro', 'visualizaciones', 'nombre_area_nro',0,1,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39]\n",
    "\n",
    "def x_categoricas():\n",
    "    return ['genero_postulante', 'maximo_nivel_educativo_postulante', 'nivel_laboral', 'tipo_de_trabajo', 'nombre_area']\n",
    "\n",
    "def x_humanas():\n",
    "    return ['id_postulante', 'id_aviso', 'titulo', 'descripcion', 'denominacion_empresa'] + x_categoricas\n",
    "\n",
    "def y_entrenamiento():\n",
    "    return ['sepostulo']\n",
    "\n",
    "def columnas_relevantes_test_data():\n",
    "    return ['id','id_aviso','id_postulante'] + x_entrenamiento()\n",
    "\n",
    "def get_test_data():\n",
    "    tests = pd.read_csv('data/Test/test_final_100k.csv')\n",
    "    columns_rename = {'idpostulante': 'id_postulante', 'idaviso': 'id_aviso'}\n",
    "    tests = tests.rename(columns=columns_rename)\n",
    "    tests = pd.merge(tests, get_avisos_detalle(), on='id_aviso', how='left')\n",
    "    tests = pd.merge(tests, get_postulantes_limpios(), on='id_postulante', how='left')\n",
    "    \n",
    "    vistas = get_vistas()\n",
    "    tests = pd.merge(tests, vistas, on=['id_postulante', 'id_aviso'], how='left' )    \n",
    "    tests['visualizaciones'].fillna(value=0, inplace=True) \n",
    "        \n",
    "    return tests[columnas_relevantes_test_data()]\n",
    "\n",
    "def get_default_null_values(df):\n",
    "    return {'edad_postulante':int(df['edad_postulante'].mean()), 'genero_postulante_nro':int(0), 'maximo_nivel_educativo_postulante':int(df['maximo_nivel_educativo_postulante'].mean()), 'nivel_laboral_nro':int(0), 'visualizaciones':int(0), 'nombre_area_nro':int(0)}\n",
    "\n",
    "\n",
    "def get_test_data_clean():\n",
    "    tests = get_test_data()\n",
    "    tests = tests.fillna(value=get_default_null_values(tests))\n",
    "    return tests\n",
    "\n",
    "def get_datos_entrenamiento(size=None):\n",
    "    postulaciones_aplicadas = get_detalle_postulaciones(size)\n",
    "    columnas_relevantes = x_entrenamiento() + y_entrenamiento()\n",
    "    postulaciones_aplicadas['sepostulo'] = True\n",
    "    postulaciones_no_aplicadas = get_detalle_vistas(size)\n",
    "    vistas = postulaciones_no_aplicadas[['id_postulante', 'id_aviso', 'visualizaciones']]        \n",
    "    postulaciones_aplicadas = pd.merge(postulaciones_aplicadas, vistas, on=['id_postulante', 'id_aviso'], how='left' )    \n",
    "    postulaciones_aplicadas['visualizaciones'].fillna(value=0, inplace=True)    \n",
    "    postulaciones_no_aplicadas['sepostulo'] = False    \n",
    "    postulaciones_aplicadas = postulaciones_aplicadas[:postulaciones_no_aplicadas.shape[0]]\n",
    "    postulaciones_no_aplicadas = postulaciones_no_aplicadas[:postulaciones_aplicadas.shape[0]]\n",
    "    return postulaciones_aplicadas.append(postulaciones_no_aplicadas).drop_duplicates(subset=['id_aviso', 'id_postulante'], keep='first')[columnas_relevantes].dropna()\n",
    "\n",
    "def get_predictor(set_entrenamiento):\n",
    "    # Prepare feature and dependent variable along with categorical encoding\n",
    "    X=pd.get_dummies(set_entrenamiento.loc[:, x_entrenamiento()])\n",
    "    y=set_entrenamiento.loc[:, 'sepostulo']\n",
    "    clf = svm.SVC()\n",
    "    return clf.fit(X, y)\n",
    "\n",
    "def get_random_forest_predictor(set_entrenamiento):\n",
    "    X = set_entrenamiento.loc[:, x_entrenamiento()]\n",
    "    Y = set_entrenamiento.loc[:, 'sepostulo']\n",
    "    clf = RandomForestClassifier(n_estimators=15)\n",
    "    return clf.fit(X, Y)\n",
    "\n",
    "def get_sgd_classifier(set_entrenamiento):\n",
    "    X = set_entrenamiento.loc[:, x_entrenamiento()]\n",
    "    Y = set_entrenamiento.loc[:, 'sepostulo']\n",
    "    clf = linear_model.SGDClassifier()\n",
    "    return clf.fit(X, Y)\n",
    "\n",
    "def get_general_predictor():\n",
    "    return get_random_forest_predictor(get_datos_entrenamiento(10000))\n",
    "\n",
    "def get_postulantes_a_personalizar():\n",
    "    tests = pd.read_csv('data/Test/test_final_100k.csv')\n",
    "    return set(tests['idpostulante'])\n",
    "\n",
    "def get_personalized_predictor(cantidad_mininima_observaciones):\n",
    "    datos_entrenamiento = get_datos_entrenamiento()\n",
    "    postulantes = get_postulantes_a_personalizar()\n",
    "    return get_random_forest_predictor(get_datos_entrenamiento(10000))\n",
    "\n",
    "#El ensamble\n",
    "def get_predictor_machine_avisos(cantidad_mininima_observaciones):\n",
    "    machine = { generalPredictor : get_general_predictor(), personalizedPredictor : get_personalized_predictor(cantidad_mininima_observaciones)} \n",
    "    return machine\n",
    "\n",
    "def obtener_predicciones(predictor, set_test):\n",
    "    return predictor.predict(set_test[x_entrenamiento()])\n",
    "\n",
    "def get_score(dataset, clasificador):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(dataset.loc[:, x_entrenamiento()], dataset.loc[:, 'sepostulo'], test_size=0.33, random_state=42)\n",
    "    clasificador = clasificador.fit(X_train, y_train)    \n",
    "    return clasificador.score(X_test, y_test)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "set_entrenamiento = get_datos_entrenamiento()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     4320492\n",
       "False    3049459\n",
       "Name: sepostulo, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_entrenamiento['sepostulo'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7369951, 47)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_entrenamiento.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edad_postulante</th>\n",
       "      <th>genero_postulante_nro</th>\n",
       "      <th>maximo_nivel_educativo_postulante</th>\n",
       "      <th>nivel_laboral_nro</th>\n",
       "      <th>visualizaciones</th>\n",
       "      <th>nombre_area_nro</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>...</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>sepostulo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   edad_postulante  genero_postulante_nro  maximo_nivel_educativo_postulante  \\\n",
       "0             37.0                    0.0                               48.0   \n",
       "1             45.0                    0.0                               44.0   \n",
       "2             46.0                    0.0                               44.0   \n",
       "3             38.0                    1.0                               44.0   \n",
       "4             47.0                    0.0                               48.0   \n",
       "\n",
       "   nivel_laboral_nro  visualizaciones  nombre_area_nro    0    1    3    4  \\\n",
       "0                2.0              0.0               58  1.0  0.0  0.0  0.0   \n",
       "1                2.0              0.0               58  1.0  0.0  0.0  0.0   \n",
       "2                2.0              0.0               58  1.0  0.0  0.0  0.0   \n",
       "3                2.0              0.0               58  1.0  0.0  0.0  0.0   \n",
       "4                2.0              0.0               58  1.0  0.0  0.0  0.0   \n",
       "\n",
       "     ...       31   32   33   34   35   36   37   38   39  sepostulo  \n",
       "0    ...      0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0       True  \n",
       "1    ...      0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0       True  \n",
       "2    ...      0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0       True  \n",
       "3    ...      0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0       True  \n",
       "4    ...      0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0       True  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_entrenamiento.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Armado de los sets de test y de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = set_entrenamiento.columns.values.tolist()\n",
    "x.remove('sepostulo')\n",
    "\n",
    "# para generar las predicciones te conviene entrenar con el dataset completo sin splitear...\n",
    "# haces el split para encontrar la mejor version de los parametros del modelo.\n",
    "X_train, X_test, y_train, y_test = train_test_split(set_entrenamiento.loc[:, x], set_entrenamiento.loc[:, 'sepostulo'], test_size=0.3, random_state=43)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#clf = RandomForestClassifier(n_estimators=30)\n",
    "clf = RandomForestClassifier(n_estimators=70,min_samples_split=10,min_samples_leaf=10)\n",
    "\n",
    "predictor =  clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8318845076359597"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prueba y resultados para la competencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'set_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-fe6fed6ba681>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mguardar_resultados\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'100K ultimo.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mset_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sepostulo'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'set_test' is not defined"
     ]
    }
   ],
   "source": [
    "def obtener_predicciones(predictor, set_test):\n",
    "    x = set_entrenamiento.columns.values.tolist()\n",
    "    x.remove('sepostulo')    \n",
    "    return predictor.predict(set_test[x]).astype(int)\n",
    "\n",
    "def guardar_resultados(fileName, predictor, set_test):\n",
    "    result = obtener_predicciones(predictor, set_test)\n",
    "    set_test['sepostulo'] = result\n",
    "    set_test[['id','sepostulo']].set_index('id').to_csv(fileName)\n",
    "    return\n",
    "\n",
    "\n",
    "guardar_resultados('100K ultimo.csv', predictor, set_test)\n",
    "set_test['sepostulo'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [anaconda2]",
   "language": "python",
   "name": "Python [anaconda2]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
