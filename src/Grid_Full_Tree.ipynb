{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import (RandomForestClassifier,GradientBoostingClassifier)\n",
    "from sklearn import linear_model\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import linear_model\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparacion de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_postulaciones(size=None):\n",
    "    postulaciones = pd.read_csv('data/FiubaHasta15Abril/fiuba_4_postulaciones.csv', nrows =size).drop_duplicates(subset=['idpostulante', 'idaviso'], keep='last')\n",
    "    columns_rename = {'idaviso': 'id_aviso', 'idpostulante': 'id_postulante', 'fechapostulacion': 'fecha_postulacion'}\n",
    "    postulaciones = postulaciones.rename(columns=columns_rename)\n",
    "    postulaciones['fecha_postulacion']=pd.to_datetime(postulaciones['fecha_postulacion'])\n",
    "    return postulaciones\n",
    "\n",
    "def get_vistas(size=None):\n",
    "    vistas1 = pd.read_csv('data/FiubaHasta15Abril/fiuba_3_vistas.csv', nrows =size)\n",
    "    vistas2 = pd.read_csv('data/FiubaDesde15Abril/fiuba_3_vistas.csv', nrows =size)\n",
    "    vistas3 = pd.read_csv('data/fiuba_3_vistas.csv', nrows =size)\n",
    "    vistas = pd.concat([vistas1, vistas2, vistas3])\n",
    "    vistas_sumarizadas = vistas.groupby(['idpostulante', 'idAviso'], as_index=False)['timestamp'].count()\n",
    "    columns_rename = {'idAviso': 'id_aviso', 'idpostulante': 'id_postulante', 'timestamp': 'visualizaciones'}\n",
    "    vistas_sumarizadas = vistas_sumarizadas.rename(columns=columns_rename)\n",
    "    \n",
    "    return vistas_sumarizadas\n",
    "\n",
    "\n",
    "def tokens(doc):\n",
    "    return (tok.lower() for tok in re.findall(r\"\\w+\", doc))\n",
    "\n",
    "\n",
    "def token_freqs(doc):\n",
    "    freq = defaultdict(int)\n",
    "    for tok in tokens(doc):\n",
    "        freq[tok] += 1\n",
    "    return freq\n",
    "\n",
    "\n",
    "def get_avisos_detalle():\n",
    "    avisos1 = pd.read_csv('data/fiuba_6_avisos_detalle.csv')\n",
    "    avisos2 = pd.read_csv('data/FiubaDesde15Abril/fiuba_6_avisos_detalle.csv')\n",
    "    avisos3 = pd.read_csv('data/FiubaHasta15Abril/fiuba_6_avisos_detalle.csv')\n",
    "    avisos4 = pd.read_csv('data/fiuba_6_avisos_detalle_missing_nivel_laboral.csv')        \n",
    "    avisos_detalle = pd.concat([avisos1,avisos2,avisos3,avisos4]).drop_duplicates(subset=['idaviso'], keep='last').reset_index(drop=True)\n",
    "    columns_rename = {'idpostulante': 'id_postulante', 'idaviso': 'id_aviso'}\n",
    "    avisos_detalle = avisos_detalle.rename(columns=columns_rename)\n",
    "    to_nivel_laboral_nro = {'Senior / Semi-Senior' : 2, 'Junior':1, 'Otro':0,\n",
    "       'Jefe / Supervisor / Responsable':3,\n",
    "       'Gerencia / Alta Gerencia / Dirección':4}\n",
    "    to_tipo_trabajo_nro={'Full-time':0, 'Part-time':1, 'Teletrabajo':2, 'Por Horas':3, 'Pasantia':4,\n",
    "       'Temporario':5, 'Por Contrato':6, 'Fines de Semana':7, 'Primer empleo':8,\n",
    "       'Voluntario':9}\n",
    "    to_nombre_area_numero = pd.Series(avisos_detalle['nombre_area'].unique()).to_dict()\n",
    "    to_nombre_area_numero  = {v: k for k, v in to_nombre_area_numero.items()}\n",
    "    avisos_detalle['nivel_laboral_nro']= avisos_detalle['nivel_laboral'].map(to_nivel_laboral_nro)\n",
    "    avisos_detalle['tipo_de_trabajo_nro'] = avisos_detalle['tipo_de_trabajo'].map(to_tipo_trabajo_nro)\n",
    "    avisos_detalle['nombre_area_nro'] = avisos_detalle['nombre_area'].map(to_nombre_area_numero)\n",
    "\n",
    "    h = FeatureHasher(n_features = 40, input_type='string', dtype='float32')\n",
    "\n",
    "    avisos_detalle['titulo_as_token_freq'] = avisos_detalle.titulo.apply(lambda x: token_freqs(x))\n",
    "    #x = h.transform(avisos_detalle['titulo'])\n",
    "    # en lugar de usar el titulo uso un token dict\n",
    "    x = h.transform(avisos_detalle['titulo_as_token_freq'])\n",
    "    avisos_detalle['titulo'] = list(x.toarray())\n",
    "\n",
    "    titulos_como_lista = avisos_detalle.titulo.apply(pd.Series)\n",
    "    avisos_detalle = pd.merge(avisos_detalle, titulos_como_lista, left_index = True, right_index = True)\n",
    "    avisos_detalle = avisos_detalle.drop(['titulo'], axis=1)  \n",
    "\n",
    "    return avisos_detalle\n",
    "\n",
    "def get_year_of_birth(postulantes_genero_edad):\n",
    "    return (pd.to_datetime\n",
    "            (postulantes_genero_edad['fechanacimiento'], errors='coerce', format='%Y-%m-%d')\n",
    "            .dt.year)\n",
    "\n",
    "def get_age(yearOfBirth):\n",
    "    return 2018 - yearOfBirth\n",
    "    \n",
    "def get_age_range(yearOfBirth):\n",
    "    age = get_age(yearOfBirth)\n",
    "    if(age<25): return 'Entre 18 y 24'\n",
    "    if(age<30): return 'Entre 25 y 30'\n",
    "    if(age<35): return 'Entre 30 y 35'\n",
    "    if(age<40): return 'Entre 35 y 40'\n",
    "    if(age<45): return 'Entre 40 y 45'\n",
    "    if(age<50): return 'Entre 45 y 50'\n",
    "    return 'Mayor de 50'\n",
    "\n",
    "def get_order_for_age_range():\n",
    "    return ['Entre 18 y 24', 'Entre 25 y 30','Entre 30 y 35','Entre 35 y 40','Entre 40 y 45','Entre 45 y 50', 'Mayor de 50']\n",
    "\n",
    "def get_postulantes_nivel_educativo_para(path):\n",
    "    postulantes_nivel_educativo = pd.read_csv(path)\n",
    "    columns_rename = {'idpostulante': 'id_postulante', 'nombre': 'formacion_postulante', 'estado': 'estado_formacion_postulante'}\n",
    "    postulantes_nivel_educativo=postulantes_nivel_educativo.rename(columns=columns_rename)\n",
    "    formacion_to_number={'Secundario' : 10, 'Otro': 20, 'Terciario/Técnico' : 30, 'Universitario' : 40, 'Posgrado' : 50,\n",
    "    'Master' : 50, 'Doctorado' : 50}\n",
    "    postulantes_nivel_educativo['formacion_postulante_numero']=postulantes_nivel_educativo['formacion_postulante'].map(formacion_to_number);\n",
    "    estado_to_number = {'En Curso': 4, 'Abandonado': 0, 'Graduado': 8}\n",
    "    postulantes_nivel_educativo['estado_formacion_postulante_numero']=postulantes_nivel_educativo['estado_formacion_postulante'].map(estado_to_number)\n",
    "    postulantes_nivel_educativo['nivel_educativo_postulante_numero'] = postulantes_nivel_educativo['formacion_postulante_numero'] + postulantes_nivel_educativo['estado_formacion_postulante_numero']\n",
    "    postulantes_nivel_educativo['nivel_educativo_postulante_texto'] = postulantes_nivel_educativo['formacion_postulante'] + ' - ' + postulantes_nivel_educativo['estado_formacion_postulante']\n",
    "    relevant_columns = ['id_postulante','nivel_educativo_postulante_texto', 'nivel_educativo_postulante_numero']\n",
    "    postulantes_nivel_educativo = postulantes_nivel_educativo[relevant_columns]\n",
    "    grouped=postulantes_nivel_educativo.groupby(['id_postulante']).agg({'nivel_educativo_postulante_numero':['max']}) \n",
    "    df=grouped.reset_index()\n",
    "    df.columns = ['id_postulante', 'maximo_nivel_educativo_postulante']\n",
    "    return df\n",
    "\n",
    "def get_postulantes_nivel_educativo():\n",
    "    postulantes1 = get_postulantes_nivel_educativo_para('data/fiuba_1_postulantes_educacion.csv')\n",
    "    postulantes2 = get_postulantes_nivel_educativo_para('data/FiubaDesde15Abril/fiuba_1_postulantes_educacion.csv')\n",
    "    postulantes3 = get_postulantes_nivel_educativo_para('data/FiubaHasta15Abril/fiuba_1_postulantes_educacion.csv')\n",
    "    return pd.concat([postulantes1,postulantes2,postulantes3]).drop_duplicates(subset=['id_postulante'], keep='last').reset_index(drop=True)\n",
    "\n",
    "def get_postulantes_genero_edad():\n",
    "    postulantes1 = pd.read_csv('data/fiuba_2_postulantes_genero_y_edad.csv')\n",
    "    postulantes2 = pd.read_csv('data/FiubaDesde15Abril/fiuba_2_postulantes_genero_y_edad.csv')\n",
    "    postulantes3 = pd.read_csv('data/FiubaHasta15Abril/fiuba_2_postulantes_genero_y_edad.csv')\n",
    "    postulantes_genero_edad = pd.concat([postulantes1,postulantes2,postulantes3]).drop_duplicates(subset=['idpostulante'], keep='last').reset_index(drop=True)\n",
    "    postulantes_genero_edad['año_nacimiento_postulante']=get_year_of_birth(postulantes_genero_edad)\n",
    "    postulantes_genero_edad['edad_postulante']=postulantes_genero_edad['año_nacimiento_postulante'].map(get_age, na_action=None)\n",
    "    postulantes_genero_edad['rango_edad_postulante']=postulantes_genero_edad['año_nacimiento_postulante'].map(get_age_range, na_action=None)\n",
    "    columns_rename = {'idpostulante': 'id_postulante', 'fechanacimiento': 'fecha_nacimiento_postulante', 'sexo': 'genero_postulante'}\n",
    "    postulantes_genero_edad = postulantes_genero_edad.rename(columns=columns_rename)\n",
    "    postulantes_genero_edad = postulantes_genero_edad[['id_postulante', 'genero_postulante', 'fecha_nacimiento_postulante', 'edad_postulante', 'rango_edad_postulante']]\n",
    "    postulantes_genero_edad['genero_postulante_nro'] = postulantes_genero_edad['genero_postulante'].map({'FEM': 0, 'MASC': 1, 'NO_DECLARA': 2})\n",
    "    return postulantes_genero_edad\n",
    "\n",
    "def get_postulantes_limpios():\n",
    "    postulantes = pd.merge(get_postulantes_genero_edad(), get_postulantes_nivel_educativo(), on='id_postulante', how='outer')\n",
    "    order_for_columns = ['id_postulante','edad_postulante', 'genero_postulante', 'genero_postulante_nro', 'maximo_nivel_educativo_postulante']\n",
    "    return postulantes[order_for_columns]\n",
    "\n",
    "def get_detalle_postulaciones(size=None):\n",
    "    postulaciones = get_postulaciones(size)\n",
    "    avisos = get_avisos_detalle()\n",
    "    postulantes = get_postulantes_limpios()\n",
    "    detalle_postulaciones = pd.merge(postulantes, postulaciones, on='id_postulante', how='inner') \n",
    "    detalle_postulaciones = pd.merge(detalle_postulaciones, avisos, on='id_aviso', how='inner')\n",
    "    \n",
    "    return detalle_postulaciones\n",
    "\n",
    "def get_detalle_vistas(size=None):\n",
    "    vistas = get_vistas(size)\n",
    "    avisos = get_avisos_detalle()\n",
    "    postulantes = get_postulantes_limpios()\n",
    "    detalle_vistas = pd.merge(postulantes, vistas, on='id_postulante', how='inner') \n",
    "    detalle_vistas = pd.merge(detalle_vistas, avisos, on='id_aviso', how='inner')\n",
    "    return detalle_vistas\n",
    "\n",
    "def x_entrenamiento():\n",
    "    return ['edad_postulante', 'genero_postulante_nro', 'maximo_nivel_educativo_postulante', 'nivel_laboral_nro', 'visualizaciones', 'nombre_area_nro',0,1,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39]\n",
    "\n",
    "def x_categoricas():\n",
    "    return ['genero_postulante', 'maximo_nivel_educativo_postulante', 'nivel_laboral', 'tipo_de_trabajo', 'nombre_area']\n",
    "\n",
    "def x_humanas():\n",
    "    return ['id_postulante', 'id_aviso', 'titulo', 'descripcion', 'denominacion_empresa'] + x_categoricas\n",
    "\n",
    "def y_entrenamiento():\n",
    "    return ['sepostulo']\n",
    "\n",
    "def columnas_relevantes_test_data():\n",
    "    return ['id','id_aviso','id_postulante'] + x_entrenamiento()\n",
    "\n",
    "def get_test_data():\n",
    "    tests = pd.read_csv('data/Test/test_final_100k.csv')\n",
    "    columns_rename = {'idpostulante': 'id_postulante', 'idaviso': 'id_aviso'}\n",
    "    tests = tests.rename(columns=columns_rename)\n",
    "    tests = pd.merge(tests, get_avisos_detalle(), on='id_aviso', how='left')\n",
    "    tests = pd.merge(tests, get_postulantes_limpios(), on='id_postulante', how='left')    \n",
    "    vistas = get_vistas()\n",
    "    tests = pd.merge(tests, vistas, on=['id_postulante', 'id_aviso'], how='left' )    \n",
    "    tests['visualizaciones'].fillna(value=0, inplace=True) \n",
    "    tests['edad_postulante'].fillna(value=0, inplace=True)\n",
    "    tests['maximo_nivel_educativo_postulante'].fillna(value=0, inplace=True)\n",
    "    tests['nivel_laboral_nro'].fillna(value=0, inplace=True)\n",
    "    tests['nombre_area_nro'].fillna(value=0, inplace=True)\n",
    "                                                  \n",
    "    return tests[columnas_relevantes_test_data()]\n",
    "\n",
    "def get_default_null_values(df):\n",
    "    return {'edad_postulante':int(df['edad_postulante'].mean()), 'genero_postulante_nro':int(0), 'maximo_nivel_educativo_postulante':int(df['maximo_nivel_educativo_postulante'].mean()), 'nivel_laboral_nro':int(0), 'visualizaciones':int(0), 'nombre_area_nro':int(0)}\n",
    "\n",
    "\n",
    "def get_test_data_clean():\n",
    "    tests = get_test_data()\n",
    "    tests = tests.fillna(value=get_default_null_values(tests))\n",
    "    return tests\n",
    "\n",
    "def get_datos_entrenamiento(size=None):\n",
    "    postulaciones_aplicadas = get_detalle_postulaciones(size)\n",
    "    columnas_relevantes = x_entrenamiento() + y_entrenamiento()\n",
    "    postulaciones_aplicadas['sepostulo'] = True\n",
    "    postulaciones_no_aplicadas = get_detalle_vistas(size)\n",
    "    vistas = postulaciones_no_aplicadas[['id_postulante', 'id_aviso', 'visualizaciones']]        \n",
    "    postulaciones_aplicadas = pd.merge(postulaciones_aplicadas, vistas, on=['id_postulante', 'id_aviso'], how='left' )    \n",
    "    postulaciones_aplicadas['visualizaciones'].fillna(value=0, inplace=True)    \n",
    "    postulaciones_no_aplicadas['sepostulo'] = False    \n",
    "    postulaciones_aplicadas = postulaciones_aplicadas[:postulaciones_no_aplicadas.shape[0]]\n",
    "    postulaciones_no_aplicadas = postulaciones_no_aplicadas[:postulaciones_aplicadas.shape[0]]\n",
    "    candidatos = postulaciones_aplicadas.append(postulaciones_no_aplicadas).drop_duplicates(subset=['id_aviso', 'id_postulante'], keep='first')[columnas_relevantes].dropna()\n",
    "    candidatos_true  = candidatos[candidatos['sepostulo']==True]\n",
    "    candidatos_false = candidatos[candidatos['sepostulo']==False]\n",
    "    candidatos_true  = candidatos_true[:candidatos_false.shape[0]]\n",
    "    candidatos_false = candidatos_false[:candidatos_true.shape[0]]\n",
    "    return candidatos_false.append(candidatos_true)\n",
    "\n",
    "\n",
    "def get_predictor(set_entrenamiento):\n",
    "    # Prepare feature and dependent variable along with categorical encoding\n",
    "    X=pd.get_dummies(set_entrenamiento.loc[:, x_entrenamiento()])\n",
    "    y=set_entrenamiento.loc[:, 'sepostulo']\n",
    "    clf = svm.SVC()\n",
    "    return clf.fit(X, y)\n",
    "\n",
    "def get_random_forest_predictor(set_entrenamiento):\n",
    "    X = set_entrenamiento.loc[:, x_entrenamiento()]\n",
    "    Y = set_entrenamiento.loc[:, 'sepostulo']\n",
    "    clf = RandomForestClassifier(n_estimators=15)\n",
    "    return clf.fit(X, Y)\n",
    "\n",
    "def get_sgd_classifier(set_entrenamiento):\n",
    "    X = set_entrenamiento.loc[:, x_entrenamiento()]\n",
    "    Y = set_entrenamiento.loc[:, 'sepostulo']\n",
    "    clf = linear_model.SGDClassifier()\n",
    "    return clf.fit(X, Y)\n",
    "\n",
    "def get_general_predictor():\n",
    "    return get_random_forest_predictor(get_datos_entrenamiento(10000))\n",
    "\n",
    "def get_postulantes_a_personalizar():\n",
    "    tests = pd.read_csv('data/Test/test_final_100k.csv')\n",
    "    return set(tests['idpostulante'])\n",
    "\n",
    "def get_personalized_predictor(cantidad_mininima_observaciones):\n",
    "    datos_entrenamiento = get_datos_entrenamiento()\n",
    "    postulantes = get_postulantes_a_personalizar()\n",
    "    return get_random_forest_predictor(get_datos_entrenamiento(10000))\n",
    "\n",
    "#El ensamble\n",
    "def get_predictor_machine_avisos(cantidad_mininima_observaciones):\n",
    "    machine = { generalPredictor : get_general_predictor(), personalizedPredictor : get_personalized_predictor(cantidad_mininima_observaciones)} \n",
    "    return machine\n",
    "\n",
    "def obtener_predicciones(predictor, set_test):\n",
    "    return predictor.predict(set_test[x_entrenamiento()])\n",
    "\n",
    "def get_score(dataset, clasificador):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(dataset.loc[:, x_entrenamiento()], dataset.loc[:, 'sepostulo'], test_size=0.33, random_state=42)\n",
    "    clasificador = clasificador.fit(X_train, y_train)    \n",
    "    return clasificador.score(X_test, y_test)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "set_entrenamiento = get_datos_entrenamiento(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     869\n",
       "False    869\n",
       "Name: sepostulo, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_entrenamiento['sepostulo'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6098918, 47)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_entrenamiento.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edad_postulante</th>\n",
       "      <th>genero_postulante_nro</th>\n",
       "      <th>maximo_nivel_educativo_postulante</th>\n",
       "      <th>nivel_laboral_nro</th>\n",
       "      <th>visualizaciones</th>\n",
       "      <th>nombre_area_nro</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>...</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>sepostulo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   edad_postulante  genero_postulante_nro  maximo_nivel_educativo_postulante  \\\n",
       "1             39.0                    1.0                               48.0   \n",
       "2             36.0                    0.0                               44.0   \n",
       "3             34.0                    0.0                               40.0   \n",
       "4             33.0                    0.0                               48.0   \n",
       "5             28.0                    1.0                               44.0   \n",
       "\n",
       "   nivel_laboral_nro  visualizaciones  nombre_area_nro    0    1    3    4  \\\n",
       "1                2.0              1.0                1  0.0  0.0  0.0  0.0   \n",
       "2                2.0              1.0                1  0.0  0.0  0.0  0.0   \n",
       "3                2.0              1.0                1  0.0  0.0  0.0  0.0   \n",
       "4                2.0              2.0                1  0.0  0.0  0.0  0.0   \n",
       "5                2.0              4.0                1  0.0  0.0  0.0  0.0   \n",
       "\n",
       "     ...       31   32   33   34   35   36   37   38   39  sepostulo  \n",
       "1    ...      0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0      False  \n",
       "2    ...      0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0      False  \n",
       "3    ...      0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0      False  \n",
       "4    ...      0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0      False  \n",
       "5    ...      0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0      False  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_entrenamiento.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Armado de los sets de test y de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = set_entrenamiento.columns.values.tolist()\n",
    "x.remove('sepostulo')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(set_entrenamiento.loc[:, x], set_entrenamiento.loc[:, 'sepostulo'], test_size=0.3, random_state=43)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Armado de una grilla de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'n_estimators': [5, 10, 15, 20], 'max_depth': [2, 5, 7, 9],\n",
    "                     'min_samples_split': [5,10,15], 'min_samples_leaf': [5,10,15]}]\n",
    "\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(RandomForestClassifier(), tuned_parameters, cv=5,\n",
    "                       scoring='%s_macro' % score)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=50,min_samples_split=10,min_samples_leaf=10)\n",
    "\n",
    "predictor =  clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8491317588469215"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prueba y resultados para la competencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    71585\n",
       "0    28415\n",
       "Name: sepostulo, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def obtener_predicciones(predictor, set_test):\n",
    "    x = set_entrenamiento.columns.values.tolist()\n",
    "    x.remove('sepostulo')    \n",
    "    return predictor.predict(set_test[x]).astype(int)\n",
    "\n",
    "def guardar_resultados(fileName, predictor, set_test):\n",
    "    result = obtener_predicciones(predictor, set_test)\n",
    "    set_test['sepostulo'] = result\n",
    "    set_test[['id','sepostulo']].set_index('id').to_csv(fileName)\n",
    "    return\n",
    "\n",
    "set_test = get_test_data()\n",
    "\n",
    "guardar_resultados('100K ultimo.csv', predictor, set_test)\n",
    "set_test['sepostulo'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
